{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ancient-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from gensim) (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from gensim) (1.20.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from gensim) (1.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: nltk in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: click in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from nltk) (1.0.0)\n",
      "Requirement already satisfied: regex in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in /Users/imayak/exper/python_nlp_venv/lib/python3.8/site-packages (from nltk) (4.56.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "!pip install gensim\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assured-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprised-central",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/imayak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "champion-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [\n",
    "    \"Human machine interface for lab abc computer and machine applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appreciated-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words = stop_words + ['com', 'edu', 'subject', 'lines', 'organization', 'would', 'article', 'could']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "filled-identifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'computer', 'machine'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# Create a set of frequent words\n",
    "#stop_words = set('for a of the and to in'.split(' '))\n",
    "# Lowercase each document, split it by white space and filter out stopwords\n",
    "texts = [[word for word in document.lower().split() if word not in stop_words]\n",
    "         for document in text_corpus]\n",
    "\n",
    "# Count word frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "# Only keep words that appear more than once\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "pprint.pprint(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gorgeous-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(13 unique tokens: ['computer', 'human', 'interface', 'machine', 'response']...)\n",
      "{'computer': 0, 'human': 1, 'interface': 2, 'machine': 3, 'response': 4, 'survey': 5, 'system': 6, 'time': 7, 'user': 8, 'eps': 9, 'trees': 10, 'graph': 11, 'minors': 12}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spare-basketball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 2)],\n",
      " [(0, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
      " [(2, 1), (6, 1), (8, 1), (9, 1)],\n",
      " [(1, 1), (6, 2), (9, 1)],\n",
      " [(4, 1), (7, 1), (8, 1)],\n",
      " [(10, 1)],\n",
      " [(10, 1), (11, 1)],\n",
      " [(10, 1), (11, 1), (12, 1)],\n",
      " [(5, 1), (11, 1), (12, 1)]]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "social-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 0.5898341626740045), (12, 0.8075244024440723)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "words = \"system minors\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outstanding-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amended-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (1, 0.32448703), (2, 0.41707572), (3, 0.7184812), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "query_document = 'system engineering'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seeing-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.7184812\n",
      "2 0.41707572\n",
      "1 0.32448703\n",
      "0 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n"
     ]
    }
   ],
   "source": [
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "effective-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)  # initialize an LSI transformation\n",
    "corpus_lsi = lsi_model[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, as_text in zip(corpus_lsi, text_corpus):\n",
    "    print(doc, as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "subject-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi_model[bow_corpus]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "settled-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"My PC is getting old\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi_model[vec_bow]  \n",
    "vec_lsi\n",
    "for doc, as_text in zip(vec_lsi, text_corpus):\n",
    "    print(doc, as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "several-tobago",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 Human machine interface for lab abc computer and machine applications\n",
      "0.0 A survey of user opinion of computer system response time\n",
      "0.0 The EPS user interface management system\n",
      "0.0 System and human system engineering testing of EPS\n",
      "0.0 Relation of user perceived response time to error measurement\n",
      "0.0 The generation of random binary unordered trees\n",
      "0.0 The intersection graph of paths in trees\n",
      "0.0 Graph minors IV Widths of trees and well quasi ordering\n",
      "0.0 Graph minors A survey\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]\n",
    "for doc, as_text in zip(sims, text_corpus):\n",
    "    print(doc, as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-squad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_nlp_venv",
   "language": "python",
   "name": "python_nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
